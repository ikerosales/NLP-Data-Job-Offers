{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# INTERACTIVE DASHBOARD\n",
    "\n",
    "> This notebook needs to be executed in a folder with all his models. Find this folder in here: [Google Drive folder](https://drive.google.com/drive/folders/1YgKDzirb00ESdaCAk8BoTtFw0bxisc8h?usp=sharing)"
   ],
   "id": "e87c3d9b0bbab25d"
  },
  {
   "cell_type": "code",
   "id": "ccc88323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:44:44.860285Z",
     "start_time": "2025-05-11T16:44:44.237613Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "9c72c935",
   "metadata": {},
   "source": [
    "# Loading Data/Models"
   ]
  },
  {
   "cell_type": "code",
   "id": "7791d185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:44:45.430607Z",
     "start_time": "2025-05-11T16:44:44.882947Z"
    }
   },
   "source": [
    "with open('df_train_with_fasttext.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "lda_model = LdaModel.load(\"best_lda_model.gensim\")\n",
    "dictionary = Dictionary.load(\"lda_dictionary.dict\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "5d6d8457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:44:46.862106Z",
     "start_time": "2025-05-11T16:44:46.835415Z"
    }
   },
   "source": [
    "lda_model.show_topics(num_topics=-1, num_words=10, log=False, formatted=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"research\" + 0.013*\"health\" + 0.009*\"development\" + 0.008*\"clinical\" + 0.008*\"include\" + 0.007*\"care\" + 0.006*\"medical\" + 0.006*\"team\" + 0.006*\"scientist\" + 0.006*\"laboratory\"'),\n",
       " (1,\n",
       "  '0.016*\"status\" + 0.014*\"employment\" + 0.013*\"opportunity\" + 0.011*\"disability\" + 0.011*\"gender\" + 0.010*\"equal\" + 0.010*\"information\" + 0.009*\"applicant\" + 0.009*\"veteran\" + 0.009*\"protect\"'),\n",
       " (2,\n",
       "  '0.034*\"business\" + 0.013*\"process\" + 0.012*\"requirement\" + 0.012*\"project\" + 0.011*\"team\" + 0.010*\"skill\" + 0.010*\"analysis\" + 0.010*\"management\" + 0.010*\"ability\" + 0.009*\"data\"'),\n",
       " (3,\n",
       "  '0.010*\"system\" + 0.008*\"management\" + 0.008*\"include\" + 0.008*\"support\" + 0.008*\"require\" + 0.008*\"position\" + 0.008*\"provide\" + 0.007*\"program\" + 0.007*\"year\" + 0.007*\"service\"'),\n",
       " (4,\n",
       "  '0.016*\"team\" + 0.011*\"data\" + 0.010*\"business\" + 0.009*\"product\" + 0.008*\"company\" + 0.008*\"build\" + 0.007*\"customer\" + 0.007*\"help\" + 0.007*\"analytic\" + 0.007*\"drive\"'),\n",
       " (5,\n",
       "  '0.029*\"data\" + 0.013*\"year\" + 0.013*\"engineer\" + 0.012*\"design\" + 0.011*\"technology\" + 0.011*\"software\" + 0.011*\"cloud\" + 0.011*\"development\" + 0.010*\"system\" + 0.009*\"engineering\"')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "88f3eaba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:44:46.924757Z",
     "start_time": "2025-05-11T16:44:46.915146Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "def get_document_topic_vector(lda_model, bow):\n",
    "    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    return np.array([prob for _, prob in sorted(topic_dist, key=lambda x: x[0])])"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6e90d18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:44:47.048331Z",
     "start_time": "2025-05-11T16:44:47.025135Z"
    }
   },
   "source": [
    "doc = data['processed_text_filtered'][0]               \n",
    "bow = dictionary.doc2bow(doc.split())      \n",
    "vec = get_document_topic_vector(lda_model, bow)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3ef6157d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:45:03.687478Z",
     "start_time": "2025-05-11T16:44:47.195868Z"
    }
   },
   "source": [
    "import spacy\n",
    "import re\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.disable_pipe('parser')\n",
    "nlp.disable_pipe('ner')\n",
    "valid_POS = set(['VERB', 'NOUN', 'ADJ', 'PROPN'])\n",
    "\n",
    "def preprocess_text(text, use_stemmer=False):\n",
    "    #text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = contractions.fix(text)\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_alpha and token.pos_ in valid_POS and not token.is_stop:\n",
    "            lemma = token.lemma_.lower()\n",
    "            if use_stemmer:\n",
    "                lemma = stemmer.stem(lemma)\n",
    "            tokens.append(lemma)\n",
    "\n",
    "    return ' '.join(tokens)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Iker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Iker\\cuarto_carrera\\proyectos_cuarto\\.venv\\lib\\site-packages\\spacy\\util.py:894: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (4.0.0.dev3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ca58d3cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:45:03.764015Z",
     "start_time": "2025-05-11T16:45:03.737989Z"
    }
   },
   "source": [
    "def get_most_probable_topic(text, lda_model, dictionary, preprocess):\n",
    "    tokens = preprocess(text)\n",
    "    bow = dictionary.doc2bow(tokens.split())\n",
    "    topic_probs = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    topic_probs = sorted(topic_probs, key=lambda x: -x[1])\n",
    "    top_topic = topic_probs[0]\n",
    "    return {\n",
    "        \"topic_id\": top_topic[0],\n",
    "        \"probability\": top_topic[1],\n",
    "        \"keywords\": lda_model.print_topic(top_topic[0])\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c7d43563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:45:03.826961Z",
     "start_time": "2025-05-11T16:45:03.803020Z"
    }
   },
   "source": [
    "def get_top_topics(text, lda_model, dictionary, preprocess, top_n=3):\n",
    "    tokens = preprocess(text)\n",
    "    bow = dictionary.doc2bow(tokens.split())\n",
    "    topic_probs = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    topic_probs = sorted(topic_probs, key=lambda x: -x[1])\n",
    "    top_topics = topic_probs[:top_n]\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"topic_id\": topic[0],\n",
    "            \"probability\": topic[1],\n",
    "            \"keywords\": lda_model.print_topic(topic[0])\n",
    "        }\n",
    "        for topic in top_topics\n",
    "    ]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "fea6dd1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:45:18.843795Z",
     "start_time": "2025-05-11T16:45:03.880072Z"
    }
   },
   "source": [
    "# This helps not to be biased by the previous TF-IDF filtering.\n",
    "texts_bow = data['processed_text'].dropna().apply(lambda x: x.split()).tolist()\n",
    "dictionary = Dictionary(texts_bow)\n",
    "# filter extremes (this is where you remove rare and too frequent words → clean BoW version)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.8)\n",
    "# create BoW corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts_bow]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e0c2502c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:04.710883Z",
     "start_time": "2025-05-11T16:45:18.895638Z"
    }
   },
   "source": [
    "import gensim.downloader as api\n",
    "# Load pretrained FastText word vectors (300 dimensions)\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "31d68f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:04.801900Z",
     "start_time": "2025-05-11T16:55:04.762286Z"
    }
   },
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "\n",
    "def get_most_similar_docs(input_text, df, vectorize, vector_col='vector', text_col='text', top_n=5):\n",
    "    input_vec = np.array(vectorize(input_text))\n",
    "    similarities = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        doc_vec = np.array(row[vector_col])\n",
    "        score = cosine_similarity(input_vec, doc_vec)\n",
    "        similarities.append((i, score))\n",
    "\n",
    "    similarities.sort(key=lambda x: -x[1])  # descending order\n",
    "\n",
    "    top_docs = [{\n",
    "        \"index\": idx,\n",
    "        \"score\": score,\n",
    "        \"text\": df.loc[idx, text_col]\n",
    "    } for idx, score in similarities[:top_n]]\n",
    "\n",
    "    return top_docs\n",
    "\n",
    "\n",
    "def vectorize(doc):\n",
    "    vectors = [fasttext_model[word] for word in doc.split() if word in fasttext_model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(fasttext_model.vector_size)  # safer than hardcoding 300\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "a31bca65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:06.680710Z",
     "start_time": "2025-05-11T16:55:04.868668Z"
    }
   },
   "source": [
    "top_docs = get_most_similar_docs(\n",
    "    input_text = data.iloc[0]['clean_text'],  \n",
    "    df = data,\n",
    "    vectorize = vectorize,            \n",
    "    vector_col = 'fasttext_vector',\n",
    "    text_col = 'clean_text',\n",
    "    top_n = 5\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "dd3a2b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:06.757700Z",
     "start_time": "2025-05-11T16:55:06.732455Z"
    }
   },
   "source": [
    "top_docs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 8816,\n",
       "  'score': 0.87493986,\n",
       "  'text': 'Agile Business Analyst 6+ month contract Jersey City, NJ YOU.S. Citizens and GC candidates are encouraged to apply. Please note this is for W2 pay only. 3rd party candidates are not accepted at this time. Please send resumes to Aleta at Aletaforbestc.com. Requirements and Responsibilities NOTE This person will be bringing Agile experience to this team as a value-add. Required Skills Minimum of 3 year Financial Services industry experience. Preferred This should be in support of financial trading or account management applications Minimum of 4 to 5 years as a Business Analyst. Required Wealth Management Highly Preferred. Financial trading experience is also preferred. Some experience in Project Management would be highly beneficial. Responsibilities Experience with various Business Analysis Methodologies including different agile disciplines. Experience with Agile methodology should include writing user stories, managing scrum calls, prioritizing backlog, etc. Proven ability to meet deadlines while simultaneously working multiple projects bull Estimates time required to deliver project artifacts and reports progress toward delivery goals throughout the project bull Leads key stakeholder analysis process bull Interacts with project stakeholders to elicit and document project requirements by translating business needs into testable, developer-ready requirements bull Produces professional quality project artifacts including but not limited to business requirement documents, requirement plans, models (e.g. data, event, context and process), traceability matrices, use cases, issue logs and other documents as needed. Ensures that system requirements meet business needs and that the business is able to fully integrate and implement new systems or system features Works with the business to recommend appropriate training, communication and scheduling as systems are deployed bull Works with the project team to determine appropriate test plans, deployment plans and supports the product launch bull Participates in the Quality Inspection process for all requirements Contact Aleta Giordano Ross Senior Recruiting Consultant Forbes Technical Consulting LLC E aletaforbestc.com mailtoaletaforbestc.com'},\n",
       " {'index': 0,\n",
       "  'score': 0.87483025,\n",
       "  'text': 'The Business Analyst will coordinate project specific deliverables to ensure successful implementation of proprietary software.\\n\\nLearn More'},\n",
       " {'index': 1889,\n",
       "  'score': 0.872714,\n",
       "  'text': 'Req ID: 97344\\n\\nNTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.\\n\\nWe are currently seeking a Sr. Business Analyst- Reporting (Cognos) to join our team in Bala Cynwyd, Pennsylvania (US-PA), United States (US).\\n\\nNTT DATA Services currently seeks a Sr Business Analyst- Reporting (Cognos) to join our team in Bala Cynwyd, PA.\\n\\nProject Deliverables:\\n\\nProject will be converting their legacy reports within SQL and SSRS to Cognos 11\\n\\nRole Responsibilities:\\n\\n- Help client evaluate the current and future sourcing for the approximately 168 150 reports deemed Non- Guidewire\\n\\n-Through a joint analysis phase (partnering with client) Make recommendations to combine or eliminate reports where possible. Recommendations for new reports may come out of this phase as well.\\n\\n- Help determine the final inventory for this project.\\n\\n- Working closely with identified client and NTT SMEs, begin the BRD documentation for the approximately 168 150 reports- (Final report list as determined in step above)\\n\\n- Participate and assist in high level planning for the project itself (working with client)\\n\\n- Analyze, define and document workflows of both the current state and to-be processes to facilitate software development and process improvement activities\\n\\n- Coordinates the functional requirements with business management and technical solutions with systems personnel to determine the most cost-effective solution. Makes recommendations in the form of proposals or white papers\\n\\n- Leads the analysis, planning, design, and evaluation of key projects to help departments achieve their goals\\n\\n- Collaborate with team members to analyze, create and implement business process improvements (and metrics) that increase value add for customers and improve morale, quality, delivery and cost\\n\\n- Guide teams to manage organizational change through careful consideration of stakeholder needs and interests, strategic relationships and persuasive communications\\n\\n- Facilitates the improvement in productivity of all assets (people, equipment, materials, and time) through identification and implementation of best practices\\n\\n- Support development of project work plans / schedules, deliverables and meetings\\n\\n- Maintain project information in master document repository\\n\\n- Liaise between the business, IT, and project manager, when applicable, to provide guidance and information\\n\\n- Instructs cross-functional teams in adapting to and understanding improvement processes and oversee process improvement projects\\n\\n- Formulate proposals for new systems and information needs by analyzing existing systems, processes and procedures and defining technical / process improvements\\n\\nBasic Qualifications:\\n\\n- 5 plus years as a Business Analyst\\n\\n- 2 plus years developing in Cognos.\\n\\nPreferences:\\n\\n- Prior Lead experience with the capability of taking ownership and leading the development team as against an individual contributor.\\n\\nAbout NTT DATA Services\\n\\nNTT DATA Services is a global business and IT services provider specializing in digital, cloud and automation across a comprehensive portfolio of consulting, applications, infrastructure and business process services. We are part of the NTT family of companies, a partner to 85 % of the Fortune 100.\\n\\nNTT DATA Services is an equal opportunity employer and will consider all qualified applicants for employment without regard to race, gender, disability, age, veteran-status, sexual orientation, gender identity, or any other class protected by law.'},\n",
       " {'index': 1687,\n",
       "  'score': 0.8717211,\n",
       "  'text': 'Bulk Extracts – Project Manager – Analyst\\n\\nJob Description:\\n\\nThe Bulk Extract Project Manager Analyst will manage client requests, project development, delivery, and ongoing maintenance of a portfolio of primarily large data extract deliverables for a leading provider of a big data, predictive analytics and forward-looking insights in CPG/retail/healthcare industries.\\n\\nThe right candidate must be organized and know how to prioritize schedules and tasks in order to handle multiple clients, projects, and deadlines. You should enjoy participating in a collaborative team environment and be able to both seek and give input when necessary.\\n\\nStrong listening, observational, interpretive, consultative and problem-solving skills are a must. You will be required to effectively and confidently communicate with clients. You will need to be able to set and manage expectations both with the client and internally, and coordinate with a cross-functional team in order to execute and deliver on time and above expectations. Approximately 0-20% travel is expected in this role.\\n\\nRoles/Responsibility:\\nClient Engagement\\nEducate internal Client Insights/Service and external client teams on extract best practices\\nSet expectations and manage the client through the extract delivery process, including helping the client design the right specifications for data extract\\nProject Management\\nDevelops project plans for new projects as well as manage existing client deliverables following project management best practices\\nWorks closely with Offshore and technology cross functional partners to monitor the production of deliverables\\nSupport enterprise/team process improvement projects and initiatives\\nQC On-going deliverables\\nManage monthly deliverables for extracts and offline reporting\\nQuality check weekly/monthly reports by comparing against client specs/prior reports\\nManage project change requests\\nProject Change Requests/Restatement\\nManage all client change requests including any restatements as required\\nDevelop implementation and communication plans to ensure all stakeholders understand the change process and timing\\nSkills Requirements:\\nA background of CPG industry is crucial. Knowledge of the retailer business side is a plus.\\nExcellent verbal and written communication.\\nAbility to maintain composure under pressure and make critical decisions and come up with creative solutions on the spot, as the implementation process contains many elements which are not in your control.\\nStrong time-management skills and ability to manage multiple clients, projects, and changing timelines.\\nPlans for, organizes and coordinates work and resources to respond to requests and to ensure project goals and timelines are met\\nConsistently acts with client satisfaction in mind and follows through on commitments to ensure the needs of the client are met\\nProvides consistent delivery of a high value experience (day after day, year after year) regardless of who happens to be on the front lines of the delivery process.\\nEnsures delivery on all client commitments; removes internal barriers to delivery\\nSound data analysis skill, experience in relational databases a plus\\n#LI-AA1'},\n",
       " {'index': 9336,\n",
       "  'score': 0.8716971,\n",
       "  'text': 'The Business Systems Analyst I is responsible for working with Client Services, and Technical Delivery(TD) staff to discover and understand business needs and translate them into system requirements. The Business Systems Analyst I is responsible for drafting all required SDLC and validation documents and facilitating the review and approval of all documents. The Business Analyst I may assist with the development and documentation of processes and procedures.\\n\\nAssist Business Systems Analyst II and Business Systems Analyst III with multiple tasks related to documentation, development and testing, and system launch.\\nParticipate in requirements definition sessions with stakeholders to capture business requirements.\\nUnderstand the functional business process across the entire organization.\\nFollows defined validation processes and produces validated documents for all initiatives.\\nUtilize all available tools and information sources to elicit requirements, including interviews/meetings, document analysis, surveys, site visits, business process descriptions, use cases, and workflow analysis.\\nDrafts all required SDLC and validation documents.\\nMay be responsible for application configuration.\\nAssist in the writing of the test plans, cases & scripts as required.\\nMay review test plans, test cases, and test scripts against requirements documentation to ensure full requirements-testing traceability.\\nFacilitates and manages the review and approval of test results, and all SDLC and validation documents.\\nUpdate requirements as needed throughout the software development lifecycle.\\nWorks closely with project management and software developers to formulate the high level technical solution.\\nIdentifies, coordinates and implements process improvement initiatives.\\nOther project work and responsibilities as required.\\n\\nEducation\\nBachelor’s degree or equivalent years of experience.\\nExperience\\n1-3 years experience functioning as IT Business Analyst or similar role.\\nCompetencies & Personal Attributes\\nAbility to communicate verbally and in writing clearly and succinctly, complex project plans, design and technical issues, as well as business and product requirements.\\nIndustry experience is a MUST\\nWorking knowledge of a System/Software Development Life Cycle (SDLC).\\nDemonstrated experience coordinating or supporting complex and/or software development projects is highly desirable.\\nAbility to work collaboratively and take direction from multiple inputs.\\nAbility to manage and meet multiple deadlines and respond to multiple requests for support.\\nCommunicates effectively with both internal and external teams. Delivers information effectively and timely. Uses interpersonal skills to build and develop relationships with internal and external team members.\\nMust have excellent analytical and problem-solving skills with proven ability to comprehend business requirements.\\nProven ability to successfully handle multiple competing priorities and deliver on-time project results with little direct supervision.\\nMust have very strong skills with Microsoft Office application to include the following: Word, Excel, Visio and PowerPoint\\nFamiliarity with cost benefit analysis is a plus.\\nFamiliarity with GCP and 21 CFR Part 11 is a plus\\nFamiliarity with SQL Queries is a plus.\\n#LI-CB1'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "d0caf1a1",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d3be71f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:17.972209Z",
     "start_time": "2025-05-11T16:55:06.855543Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "## Load it later\n",
    "df_train = pd.read_pickle(\"df_train_with_all_vector_embe.pkl\")\n",
    "df_test = pd.read_pickle(\"df_test_with_all_vector_embe.pkl\")\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_df(df_train, df_test, df_vector_column: str): \n",
    "    # structured features \n",
    "    # (we drop Job Title and Description as its obvious)\n",
    "    categorical_cols = ['Company Name', 'Location', 'Headquarters', 'Size', 'Type of ownership',\n",
    "                        'Industry', 'Sector', 'Revenue']\n",
    "    # 'Low_salary_estimate (K)' removed because it would make no sense\n",
    "    numerical_cols = ['Rating', ]\n",
    "\n",
    "    # target variable\n",
    "    target_col = 'High_salary_estimate (K)'\n",
    "\n",
    "    # Replace rare categories in both train and test with 'Other'\n",
    "    def replace_rare(df_train, df_test, col):\n",
    "        freq = df_train[col].value_counts()\n",
    "        rare_vals = freq[freq == 1].index\n",
    "        df_train[col] = df_train[col].replace(rare_vals, 'Other')\n",
    "        df_test[col] = df_test[col].replace(rare_vals, 'Other')  # align with train\n",
    "        return df_train, df_test\n",
    "        \n",
    "    for col in categorical_cols:\n",
    "        df_train, df_test = replace_rare(df_train, df_test, col)\n",
    "\n",
    "    # Build feature sets\n",
    "    X_struct_train = df_train[categorical_cols + numerical_cols].copy()\n",
    "    X_struct_train[df_vector_column] = df_train[df_vector_column]\n",
    "    y_train = df_train[target_col]\n",
    "\n",
    "    X_struct_test = df_test[categorical_cols + numerical_cols].copy()\n",
    "    X_struct_test[df_vector_column] = df_test[df_vector_column]\n",
    "    y_test = df_test[target_col]\n",
    "\n",
    "\n",
    "    # custom transformer to pass FastText matrix into the pipeline\n",
    "    class VectorEmbedder(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, vector_column):\n",
    "            self.vector_column = vector_column\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            # Assumes each row in the column is a 1D NumPy array\n",
    "            return np.vstack(X[self.vector_column].values)\n",
    "\n",
    "    # preprocess structured features\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "        (\"num\", numeric_transformer, numerical_cols)\n",
    "    ])\n",
    "\n",
    "    # combine structured features + vector text\n",
    "    combined_features = FeatureUnion([\n",
    "        (\"structured\", preprocessor),\n",
    "        (\"vector_embeddings\", VectorEmbedder(vector_column=df_vector_column))\n",
    "    ])\n",
    "\n",
    "    # Transform full train/test sets\n",
    "    X_train_combined = combined_features.fit_transform(X_struct_train)\n",
    "    X_test_combined = combined_features.transform(X_struct_test)\n",
    "\n",
    "    return X_train_combined, X_test_combined, y_train, y_test\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, dropout_rate):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout(F.relu(self.bn3(self.fc3(x))))\n",
    "        x = self.fc4(x) \n",
    "        return x\n",
    "    \n",
    "X_train_combined, X_test_combined, y_train, y_test = preprocess_df(df_train, df_test, df_vector_column = \"fasttext_vector\")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_combined, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 128 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # i only need shuffled in train because we do not need order to predict in val or test set\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model, loss function and optimizer\n",
    "input_size = X_train_tensor.shape[1]  \n",
    "model_mlp = SimpleMLP(input_size=input_size, dropout_rate=0.4).to(device)\n",
    "optimizer = torch.optim.AdamW(model_mlp.parameters(), lr=0.001, weight_decay=0.01) # higher weight_decay, stronger regularization\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-5)# T_max = Number of steps (usually epochs) to anneal over, #eta_min =Minimum learning rate\n",
    "criterion = nn.MSELoss()\n",
    "myMOdel = model_mlp.load_state_dict(torch.load(\"best_mlp_fasttext.pt\", weights_only=True))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "a89e47de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:18.002915Z",
     "start_time": "2025-05-11T16:55:17.987512Z"
    }
   },
   "source": [
    "def preprocess_single_row(df_row, combined_features, categorical_cols, numerical_cols, df_vector_column):\n",
    "    if isinstance(df_row, pd.Series):\n",
    "        df_row = df_row.to_frame().T\n",
    "\n",
    "    X_struct = df_row[categorical_cols + numerical_cols].copy()\n",
    "    X_struct[df_vector_column] = df_row[df_vector_column]\n",
    "\n",
    "    return combined_features.transform(X_struct).squeeze()\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "0ea234fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:19.138982Z",
     "start_time": "2025-05-11T16:55:18.146001Z"
    }
   },
   "source": [
    "categorical_cols = ['Company Name', 'Location', 'Headquarters', 'Size', 'Type of ownership',\n",
    "                        'Industry', 'Sector', 'Revenue']\n",
    "    # 'Low_salary_estimate (K)' removed because it would make no sense\n",
    "numerical_cols = ['Rating', ]\n",
    "\n",
    "    # target variable\n",
    "target_col = 'High_salary_estimate (K)'\n",
    "df_vector_column = \"fasttext_vector\"\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "numeric_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer([\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "        (\"num\", numeric_transformer, numerical_cols)\n",
    "    ])\n",
    "class VectorEmbedder(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, vector_column):\n",
    "            self.vector_column = vector_column\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            # Assumes each row in the column is a 1D NumPy array\n",
    "            return np.vstack(X[self.vector_column].values)\n",
    "        \n",
    "combined_features = FeatureUnion([\n",
    "        (\"structured\", preprocessor),\n",
    "        (\"vector_embeddings\", VectorEmbedder(vector_column=df_vector_column))\n",
    "])\n",
    "\n",
    "X_struct_train = df_train[categorical_cols + numerical_cols].copy()\n",
    "X_struct_train[df_vector_column] = df_train[df_vector_column]\n",
    "X_train_combined = combined_features.fit_transform(X_struct_train)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "c7da6e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:19.386247Z",
     "start_time": "2025-05-11T16:55:19.315989Z"
    }
   },
   "source": [
    "to_test = preprocess_single_row(data.iloc[[0]], combined_features, categorical_cols, numerical_cols, df_vector_column)\n",
    "to_test.shape\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3017,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "b3c18464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:55:19.634123Z",
     "start_time": "2025-05-11T16:55:19.565105Z"
    }
   },
   "source": [
    "# Set model to eval mode\n",
    "model_mlp.eval()\n",
    "\n",
    "# Pick a single sample and prepare it\n",
    "sample_input = torch.tensor(to_test, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    prediction = model_mlp(sample_input)\n",
    "\n",
    "print(\"Prediction of High_salary_estimate (K):\", round(prediction.item(), 2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of High_salary_estimate (K): 126.03\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "d21ac23b",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2c6171f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T19:56:22.793285Z",
     "start_time": "2025-05-11T19:55:44.281158Z"
    }
   },
   "source": [
    "import dash\n",
    "from dash import html, dcc, Output, Input\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly.express as px\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "categorical_cols = ['Company Name', 'Location', 'Headquarters', 'Size', 'Type of ownership', 'Industry', 'Sector', 'Revenue']\n",
    "numerical_cols = ['Rating']\n",
    "df_vector_column = 'fasttext_vector'\n",
    "all_feature_names = categorical_cols + numerical_cols + [df_vector_column]\n",
    "\n",
    "# Layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.H1(\"Data Careers Dashboard\", style={\n",
    "            'text-align': 'center',\n",
    "            'color': 'white',\n",
    "            'margin': '0'\n",
    "        }),\n",
    "        html.Div([\n",
    "            html.H3(\n",
    "                \"Enter a job offer description to discover its most relevant topics. You will see the top topic probabilities along with their main keywords, and a list of the most semantically similar job postings.\",\n",
    "                style={\n",
    "                    'color': 'white',\n",
    "                    'margin': '15px 0 20px 0',\n",
    "                    'font-weight': 'normal',\n",
    "                    'line-height': '1.4',\n",
    "                    'text-align': 'center'\n",
    "                }\n",
    "            )\n",
    "        ], style={\n",
    "            'max-width': '800px',\n",
    "            'margin': '0 auto'\n",
    "        })\n",
    "    ], style={\n",
    "        'background-color': '#003366',\n",
    "        'padding': '40px 20px',\n",
    "        'margin-bottom': '20px',\n",
    "        'font-family': '\"Times New Roman\", Times, serif',\n",
    "        'border-top-left-radius': '20px',\n",
    "        'border-top-right-radius': '20px'\n",
    "    })\n",
    "    ,\n",
    "\n",
    "    html.Div(\"Job Offer Topics, Salary Prediction and Recommendations\", style={\n",
    "        'margin': '10px 0 20px 0',\n",
    "        'text-align': 'center',\n",
    "        'font-size': '20px',\n",
    "        'font-weight': 'bold',\n",
    "        'color': '#003366',\n",
    "        'border-top': '2px solid #003366',\n",
    "        'border-bottom': '2px solid #003366',\n",
    "        'padding': '20px 0'\n",
    "        \n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(col),\n",
    "            dcc.Input(\n",
    "                id=f'input-{col.lower().replace(\" \", \"-\")}',\n",
    "                type='text',\n",
    "                placeholder=f'Enter {col}',\n",
    "                style={'width': '100%'}\n",
    "            )\n",
    "        ], style={'padding': '5px', 'width': '24%'})\n",
    "        for col in categorical_cols + numerical_cols\n",
    "    ], style={\n",
    "        'display': 'flex',\n",
    "        'flex-wrap': 'wrap',\n",
    "        'gap': '10px',\n",
    "        'padding': '0 40px',\n",
    "        'margin-bottom': '20px'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Textarea(\n",
    "                id='input-text',\n",
    "                placeholder='Enter your job description here...',\n",
    "                style={'width': '100%', 'height': 250}\n",
    "            ),\n",
    "            html.Button(\"Predict\", id='submit-btn', n_clicks=0, style={'margin-top': '0px'})\n",
    "        ], style={'width': '50%', 'padding': '5px', 'box-sizing': 'border-box'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Div(id='output-topic')\n",
    "        ], style={'width': '50%', 'padding': '0px 20px 20px 20px', 'box-sizing': 'border-box'})\n",
    "    ], style={\n",
    "        'display': 'flex',\n",
    "        'justify-content': 'space-between',\n",
    "        'padding': '0 40px'\n",
    "    }),\n",
    "\n",
    "    html.Div(id='salary-prediction-output', style={\n",
    "        'textAlign': 'center',\n",
    "        'fontSize': '22px',\n",
    "        'color': '#003366',\n",
    "        'padding': '20px'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        html.H4(\"Most Similar Job Offers:\", style={'color': '#003366'}),\n",
    "        html.Div(id='similar-docs-output'),\n",
    "\n",
    "        html.Div(\"LDA Topic Understanding\", style={\n",
    "            'margin': '60px 0 20px 0',\n",
    "            'text-align': 'center',\n",
    "            'font-size': '20px',\n",
    "            'font-weight': 'bold',\n",
    "            'color': '#003366',\n",
    "            'border-top': '2px solid #003366',\n",
    "            'border-bottom': '2px solid #003366',\n",
    "            'padding': '20px 0'\n",
    "        })\n",
    "    ], style={\n",
    "        'width': '100%',\n",
    "        'padding': '0 40px',\n",
    "        'box-sizing': 'border-box'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        html.Iframe(\n",
    "            src='/assets/lda_vis.html',\n",
    "            style={'width': '80%', 'height': '800px', 'border': 'none'}\n",
    "        )\n",
    "    ], style={\n",
    "        'display': 'flex',\n",
    "        'justify-content': 'center',\n",
    "        'width': '100%',\n",
    "        'height': '850px',\n",
    "        'overflow': 'hidden',\n",
    "        'padding': '20px',\n",
    "        'box-sizing': 'border-box'\n",
    "    }),\n",
    "\n",
    "    html.Div(\"Distinctive Words by Salary Range (TF-IDF Contrast) and Job Title WordCloud\", style={\n",
    "        'margin': '60px 0 20px 0',\n",
    "        'text-align': 'center',\n",
    "        'font-size': '20px',\n",
    "        'font-weight': 'bold',\n",
    "        'color': '#003366',\n",
    "        'border-top': '2px solid #003366',\n",
    "        'border-bottom': '2px solid #003366',\n",
    "        'padding': '20px 0'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.RangeSlider(\n",
    "            id='salary-range-slider',\n",
    "            min=int(data['High_salary_estimate (K)'].min()),\n",
    "            max=int(data['High_salary_estimate (K)'].max()),\n",
    "            step=1,\n",
    "            value=[\n",
    "                int(data['High_salary_estimate (K)'].quantile(0.25)),\n",
    "                int(data['High_salary_estimate (K)'].quantile(0.75))\n",
    "            ],\n",
    "            marks={i: str(i) for i in range(\n",
    "                int(data['High_salary_estimate (K)'].min()),\n",
    "                int(data['High_salary_estimate (K)'].max()) + 1,\n",
    "                20\n",
    "            )},\n",
    "            tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "        ),\n",
    "\n",
    "        html.Div(id='range-display', style={'margin': '20px 0', 'textAlign': 'center'}),\n",
    "        dcc.Graph(id='distinctive-words-graph'),\n",
    "\n",
    "        html.H3(\"Most Common Job Titles\", style={\n",
    "            'textAlign': 'center',\n",
    "            'marginTop': '40px',\n",
    "            'color': '#003366'\n",
    "        }),\n",
    "        html.Img(id='wordcloud-img', style={\n",
    "            'display': 'block',\n",
    "            'margin': '0 auto',\n",
    "            'maxWidth': '100%'\n",
    "        })\n",
    "    ], style={\n",
    "        'margin-left': '40px',\n",
    "        'margin-right': '40px'\n",
    "    }),\n",
    "\n",
    "    html.Footer(\"Made by Team: Iker Rosales Saiz, Cesar Álvarez-Cascos Hervías, Segio Vizcaíno Ferrer and Alejandro Ponce Fernández\", style={\n",
    "        'textAlign': 'center',\n",
    "        'padding': '20px',\n",
    "        'background-color': '#f0f0f0',\n",
    "        'color': '#555',\n",
    "        'margin-top': '40px',\n",
    "        'fontStyle': 'italic'\n",
    "    })\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "\n",
    "def get_top_topics(text, lda_model, dictionary, preprocess, top_n=3):\n",
    "    tokens = preprocess(text)\n",
    "    bow = dictionary.doc2bow(tokens.split())\n",
    "    topic_probs = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    topic_probs = sorted(topic_probs, key=lambda x: -x[1])\n",
    "    return [{\n",
    "        \"topic_id\": topic[0],\n",
    "        \"probability\": topic[1],\n",
    "        \"keywords\": lda_model.print_topic(topic[0])\n",
    "    } for topic in topic_probs[:top_n]]\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    norm1, norm2 = np.linalg.norm(vec1), np.linalg.norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "\n",
    "def get_most_similar_docs(input_text, df, vectorize, vector_col='vector', text_col='text', top_n=5):\n",
    "    input_vec = np.array(vectorize(input_text))\n",
    "    similarities = [\n",
    "        (i, cosine_similarity(input_vec, np.array(row[vector_col])))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    similarities.sort(key=lambda x: -x[1])\n",
    "    return [{\n",
    "        \"index\": idx,\n",
    "        \"similarity\": score,\n",
    "        \"text\": df.loc[idx, text_col]\n",
    "    } for idx, score in similarities[:top_n]]\n",
    "\n",
    "def get_distinctive_words(df, salary_min, salary_max, top_n=20):\n",
    "    A = df[(df['High_salary_estimate (K)'] >= salary_min) & (df['High_salary_estimate (K)'] <= salary_max)]\n",
    "    B = df[~df.index.isin(A.index)]\n",
    "\n",
    "    corpus_A = A['clean_text'].dropna().astype(str).tolist()\n",
    "    corpus_B = B['clean_text'].dropna().astype(str).tolist()\n",
    "\n",
    "    if len(corpus_A) < 3 or len(corpus_B) < 3:\n",
    "        return pd.DataFrame(columns=['word', 'score'])\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', min_df=3, token_pattern=r'\\b\\w{4,}\\b')\n",
    "    vectorizer.fit(corpus_A + corpus_B)\n",
    "\n",
    "    tfidf_A = vectorizer.transform(corpus_A).mean(axis=0)\n",
    "    tfidf_B = vectorizer.transform(corpus_B).mean(axis=0)\n",
    "\n",
    "    tfidf_A = np.asarray(tfidf_A).flatten()\n",
    "    tfidf_B = np.asarray(tfidf_B).flatten()\n",
    "\n",
    "    diff = tfidf_A - tfidf_B\n",
    "    words = np.array(vectorizer.get_feature_names_out())\n",
    "    top_idx = np.argsort(diff)[-top_n:][::-1]\n",
    "\n",
    "    return pd.DataFrame({'word': words[top_idx], 'score': diff[top_idx]})\n",
    "\n",
    "def update_graph(salary_range):\n",
    "    salary_min, salary_max = salary_range\n",
    "\n",
    "    display_text = f\"Showing distinctive words for jobs with salary between {salary_min}K and {salary_max}K\"\n",
    "\n",
    "    df_words = get_distinctive_words(data, salary_min, salary_max)\n",
    "\n",
    "    if df_words.empty:\n",
    "        fig = px.bar(title=\"Not enough data to compute distinctive words\")\n",
    "    else:\n",
    "        fig = px.bar(df_words, x='word', y='score',\n",
    "                     title=f\"Top Distinctive Words ({salary_min}K–{salary_max}K)\",\n",
    "                     labels={'score': 'TF-IDF Difference'},\n",
    "                     color='score', color_continuous_scale='Blues')\n",
    "        fig.update_layout(\n",
    "            plot_bgcolor='#ffffff',         # inside chart background\n",
    "            paper_bgcolor='#ffffff',        # around the chart\n",
    "            font=dict(color='#003366'),     # text color\n",
    "            xaxis=dict(gridcolor='white', color='#003366'),\n",
    "            yaxis=dict(gridcolor='white', color='#003366'),\n",
    "            title=dict(font=dict(size=18, color='#003366'))\n",
    "        )\n",
    "\n",
    "    return display_text, fig\n",
    "\n",
    "def generate_wordcloud(df):\n",
    "    text = ' '.join(df['Job Title'].dropna().astype(str).tolist())\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        max_words=60,                  # fewer words\n",
    "        prefer_horizontal=0.95,        # strongly prefer horizontal\n",
    "        colormap='Blues',              # optional: color scheme\n",
    "        contour_color='lightgray',     # optional: soft outline\n",
    "        contour_width=1\n",
    "    ).generate(text)\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    wordcloud.to_image().save(buffer, format='PNG')\n",
    "    encoded_image = base64.b64encode(buffer.getvalue()).decode()\n",
    "    return f'data:image/png;base64,{encoded_image}'\n",
    "\n",
    "# -----------------------------\n",
    "# Callbacks\n",
    "# -----------------------------\n",
    "\n",
    "@app.callback(\n",
    "    Output('range-display', 'children'),\n",
    "    Output('distinctive-words-graph', 'figure'),\n",
    "    Output('output-topic', 'children'),\n",
    "    Output('similar-docs-output', 'children'),\n",
    "    Output('salary-prediction-output', 'children'),\n",
    "    Output('wordcloud-img', 'src'),\n",
    "    Input('salary-range-slider', 'value'),\n",
    "    Input('submit-btn', 'n_clicks'),\n",
    "    Input('input-text', 'value'),\n",
    "    *[Input(f'input-{col.lower().replace(\" \", \"-\")}', 'value') for col in categorical_cols + numerical_cols]\n",
    ")\n",
    "def update_output(salary_range, n_clicks, text, *input_values):\n",
    "    display_text, fig = update_graph(salary_range)\n",
    "\n",
    "    # Filter data for wordcloud\n",
    "    salary_min, salary_max = salary_range\n",
    "    df_filtered = data[(data['High_salary_estimate (K)'] >= salary_min) & (data['High_salary_estimate (K)'] <= salary_max)]\n",
    "    wordcloud_src = generate_wordcloud(df_filtered)\n",
    "\n",
    "    if isinstance(n_clicks, int) and n_clicks > 0 and text:\n",
    "        input_dict = dict(zip(categorical_cols + numerical_cols, input_values))\n",
    "        input_dict['Job Description'] = text\n",
    "        df = pd.DataFrame([input_dict])\n",
    "\n",
    "        df['fasttext_vector'] = [vectorize(df['Job Description'].iloc[0])]\n",
    "        for col in numerical_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col].fillna(3.780978090766823, inplace=True)\n",
    "\n",
    "        to_test = preprocess_single_row(df.iloc[[0]], combined_features, categorical_cols, numerical_cols, df_vector_column)\n",
    "        model_mlp.eval()\n",
    "        sample_input = torch.tensor(to_test, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            prediction = model_mlp(sample_input)\n",
    "        salary_estimate = round(prediction.item(), 2)\n",
    "\n",
    "        num_topics = lda_model.num_topics\n",
    "        \n",
    "        topic_names = {\n",
    "            0: \"Healthcare & Research\",\n",
    "            1: \"Equality Consciousness\",\n",
    "            2: \"Business Analysts & Project Management\",\n",
    "            3: \"Management & High paid roles\",\n",
    "            4: \"Data Science & ML\",\n",
    "            5: \"Data Engineering & Cloud\"\n",
    "        }\n",
    "        \n",
    "        results = get_top_topics(text, lda_model, dictionary, preprocess_text, top_n=num_topics)\n",
    "        \n",
    "        # Mapping\n",
    "        topic_labels = [topic_names.get(res['topic_id'], f\"Topic {res['topic_id']}\") for res in results]\n",
    "        \n",
    "        bar_chart = dcc.Graph(\n",
    "            figure=go.Figure(\n",
    "                data=[\n",
    "                    go.Bar(\n",
    "                        y=topic_labels,\n",
    "                        x=[res['probability'] for res in results],\n",
    "                        text=[f\"{res['probability']:.4f}\" for res in results],\n",
    "                        textposition='outside',\n",
    "                        orientation='h',\n",
    "                        marker=dict(color='rgba(30, 144, 255, 0.8)', line=dict(width=1, color='white')),\n",
    "                        hoverinfo='x+y'\n",
    "                    )\n",
    "                ],\n",
    "                layout=go.Layout(\n",
    "                    title=dict(text=\"Topic Probabilities\", font=dict(size=20, color='#003366')),\n",
    "                    xaxis=dict(\n",
    "                        title=\"Probability\",\n",
    "                        gridcolor='lightgrey',\n",
    "                        color='#003366',  # Eje X en azul oscuro\n",
    "                        titlefont=dict(color='#003366'),\n",
    "                        tickfont=dict(color='#003366')\n",
    "                    ),\n",
    "                    yaxis=dict(\n",
    "                        title=\"Topic\",\n",
    "                        categoryorder='array',\n",
    "                        categoryarray=topic_labels,\n",
    "                        titlefont=dict(color='#003366'),   # Color del título del eje Y\n",
    "                        tickfont=dict(color='#003366')     # Color de las etiquetas del eje Y\n",
    "                    ),\n",
    "                    height=30 * num_topics + 120,\n",
    "                    plot_bgcolor='white',\n",
    "                    paper_bgcolor='white',\n",
    "                    font=dict(color='#003366'),\n",
    "                    margin=dict(l=180, r=20, t=60, b=40)  # l aumentado para que no se corte\n",
    "                )\n",
    "\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        similar_docs = get_most_similar_docs(text, data, vectorize, vector_col='fasttext_vector', text_col='clean_text', top_n=5)\n",
    "        collapsibles = html.Div([\n",
    "            html.Details([\n",
    "                html.Summary(\n",
    "                    f\"Top {i+1} - Similarity: {doc['similarity']:.4f} - {data.loc[doc['index'], 'Job Title']} at {data.loc[doc['index'], 'Company Name']}\"\n",
    "                ),\n",
    "                html.P([html.Strong(\"Job Title: \"), data.loc[doc['index'], 'Job Title']]),\n",
    "                html.P([html.Strong(\"Company Name: \"), data.loc[doc['index'], 'Company Name']]),\n",
    "                html.P([html.Strong(\"Salary Range: \"), f\"{data.loc[doc['index'], 'Low_salary_estimate (K)']}K - {data.loc[doc['index'], 'High_salary_estimate (K)']}K\"]),\n",
    "                html.P(doc['text'])\n",
    "            ], style={\n",
    "                'margin-bottom': '15px',\n",
    "                'padding': '15px',\n",
    "                'border': '1px solid #ccc',\n",
    "                'border-radius': '10px',\n",
    "                'box-shadow': '0 2px 5px rgba(0, 0, 0, 0.05)',\n",
    "                'background-color': 'white'\n",
    "            })\n",
    "            for i, doc in enumerate(similar_docs)\n",
    "        ])\n",
    "\n",
    "        return display_text, fig, html.Div([bar_chart]), collapsibles, html.H4(f\"Predicted High Salary Estimate (K): {salary_estimate}\"), wordcloud_src\n",
    "\n",
    "    return display_text, fig, \"\", \"\", \"\", wordcloud_src\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Execute app\n",
    "# -----------------------------\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25ceff963d0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
